# What do language models really understand?

**Course Description**: Large language models such as GPT-3 and ChatGPT have led to great advances in the field of natural language processing, and in many cases they provide responses to prompts that suggest that possess non-trivial abilities to understand language. At the same time, however, these models are primarily trained on text and have no explicit connection with the real world, whereas humans learn language by interacting with other humans and forming associations between words and phrases and entities and events in the world.

In this seminar, we will focus on the question to what extent large language models understand language. We'll cover different philosophical schools of what it means to understand language, and then focus on a series of recent empirical papers that aim to evaluate different aspects of language understanding in models.

**Time**: Thursdays, 2:15-3:45pm

**Room**: C7.3 1.12

### Syllabus

Exact readings are still subject to change!

|    Date    |                                         Topic                                        |                        Papers                        | Presenter |
|:----------:|:------------------------------------------------------------------------------------:|:----------------------------------------------------:|:---------:|
| 04/13/2023 |                          Foundations: Large Language Models                          |       [Devlin et al. (2019)](https://aclanthology.org/N19-1423/), [Brown et al. (2020)](https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf)      | Sebastian |
| 04/20/2023 |        Foundations: Fine-tuning and reinforcement learning from human feedback       |                 [Ouyang et al. (2022)](https://arxiv.org/abs/2203.02155)                 | Sebastian |
| 04/27/2023 | Foundations: What does it mean to 'understand'? Methods for assessing understanding. | [Bender and Koller (2020)](https://aclanthology.org/2020.acl-main.463/), [Piantadosi and Hill (2022)](https://arxiv.org/abs/2208.02957) | Sebastian |
| 05/04/2023 |                      Methods: Behavioral experiments and probing                     |      [Linzen et al. (2016)](https://aclanthology.org/Q16-1037/), [Tenney et al. (2019)](https://aclanthology.org/S19-1026/)      |           |
| 05/11/2023 |                     Negation                     |      [Ettinger (2020)](https://aclanthology.org/2020.tacl-1.3/), [Shivagunde et al. (2023)](https://arxiv.org/abs/2303.16445) ?      |           |
| 05/16/2023 (Special day/time!) |                     Compositionality                     |      [Kim and Linzen (2020)](https://aclanthology.org/2020.emnlp-main.731/), [Qiu et al. (2022)](https://aclanthology.org/2022.emnlp-main.624/)     |           |
| 05/18/2023 |                        _no class_ (public holiday)                  |         |           |
| 05/25/2023 |                      Entity tracking / world models I                       |      Li et al. (2021), Kim and Schuster (to appear)    |           |
| 06/01/2023 |                        Entity tracking / world models II                    |   Toshniwal et al. (2021), Li et al. (2023)      |           |
| 06/06/2023 (Special day/time!) |  Discourse understading and connectives                                   |   Pandia and Ettinger (2021), Pandia et al. (2021)       |           |
| 06/08/2023 |                      _no class_ (public holiday)                    |        |           |
| 06/15/2023 |                        Pragmatic inferences                   |  Hu et al. (2022), Ruis et al. (2022)        |           |
| 06/22/2023 |                       Metaphors / Figurative meaning                       | TBD     |           |
| 06/29/2023 |                        Grounding I             |   TBD     |           |
| 07/06/2023 |                        Grounding II            |  TBD   |           |
| 07/11/2023 |                       _no class_           |     |           |
| 07/18/2023 |                       _no class_           |     |           |




