# What do language models really understand?

**Course Description**: Large language models such as GPT-3 and ChatGPT have led to great advances in the field of natural language processing, and in many cases they provide responses to prompts that suggest that possess non-trivial abilities to understand language. At the same time, however, these models are primarily trained on text and have no explicit connection with the real world, whereas humans learn language by interacting with other humans and forming associations between words and phrases and entities and events in the world.

In this seminar, we will focus on the question to what extent large language models understand language. We'll cover different philosophical schools of what it means to understand language, and then focus on a series of recent empirical papers that aim to evaluate different aspects of language understanding in models.

**Time**: Thursdays, 2:15-3:45pm

**Room**: C7.3 1.12

### Syllabus

Coming soon.

|    Date    |                                         Topic                                        |                        Papers                        | Presenter |
|:----------:|:------------------------------------------------------------------------------------:|:----------------------------------------------------:|:---------:|
| 04/13/2023 |                          Foundations: Large Language Models                          |       Devlin et al. (2019), Brown et al. (2020)      | Sebastian |
| 04/20/2023 |        Foundations: Fine-tuning and reinforcement learning from human feedback       |                 Ouyang et al. (2022)                 | Sebastian |
| 04/27/2023 | Foundations: What does it mean to 'understand'? Methods for assessing understanding. | Bender and Koller (2020), Piantadosi and Hill (2022) | Sebastian |
| 05/04/2023 |                      Methods: Behavioral experiments and probing                     |      Linzen et al. (2016), Tenney et al. (2019)      |           |
